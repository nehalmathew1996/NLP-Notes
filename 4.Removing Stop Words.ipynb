{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276d33ae",
   "metadata": {},
   "source": [
    "# Need to remove stopwords\n",
    "\n",
    "Stop words are available in abundance in any human language. By removing these words, we remove the low-level information from our text in order to give more focus to the important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e9250",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0c09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89e464",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93ec6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3220, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>background_image_url</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.263846e+17</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>2017-01-31 11:00:07</td>\n",
       "      <td>The President's address wonderfully encapsulat...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>26809964.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Prime Minister of India</td>\n",
       "      <td>India</td>\n",
       "      <td>http://pbs.twimg.com/profile_background_images...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.263843e+17</td>\n",
       "      <td>907.0</td>\n",
       "      <td>2877.0</td>\n",
       "      <td>2017-01-31 10:59:12</td>\n",
       "      <td>Rashtrapati Ji's address to both Houses of Par...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>26809964.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Prime Minister of India</td>\n",
       "      <td>India</td>\n",
       "      <td>http://pbs.twimg.com/profile_background_images...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.263827e+17</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-01-31 10:52:33</td>\n",
       "      <td>RT @PMOIndia: Empowering the marginalised. htt...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>26809964.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Prime Minister of India</td>\n",
       "      <td>India</td>\n",
       "      <td>http://pbs.twimg.com/profile_background_images...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.263826e+17</td>\n",
       "      <td>666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-01-31 10:52:22</td>\n",
       "      <td>RT @PMOIndia: Commitment to welfare of farmers...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>26809964.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Prime Minister of India</td>\n",
       "      <td>India</td>\n",
       "      <td>http://pbs.twimg.com/profile_background_images...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.263826e+17</td>\n",
       "      <td>716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-01-31 10:52:16</td>\n",
       "      <td>RT @PMOIndia: Improving the quality of life fo...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>26809964.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Prime Minister of India</td>\n",
       "      <td>India</td>\n",
       "      <td>http://pbs.twimg.com/profile_background_images...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  retweets_count  favorite_count           created_at  \\\n",
       "0  8.263846e+17          1406.0          4903.0  2017-01-31 11:00:07   \n",
       "1  8.263843e+17           907.0          2877.0  2017-01-31 10:59:12   \n",
       "2  8.263827e+17           694.0             0.0  2017-01-31 10:52:33   \n",
       "3  8.263826e+17           666.0             0.0  2017-01-31 10:52:22   \n",
       "4  8.263826e+17           716.0             0.0  2017-01-31 10:52:16   \n",
       "\n",
       "                                                text lang  retweeted  \\\n",
       "0  The President's address wonderfully encapsulat...   en      False   \n",
       "1  Rashtrapati Ji's address to both Houses of Par...   en      False   \n",
       "2  RT @PMOIndia: Empowering the marginalised. htt...   en      False   \n",
       "3  RT @PMOIndia: Commitment to welfare of farmers...   en      False   \n",
       "4  RT @PMOIndia: Improving the quality of life fo...   en      False   \n",
       "\n",
       "   followers_count  friends_count  hashtags_count              description  \\\n",
       "0       26809964.0         1641.0             1.0  Prime Minister of India   \n",
       "1       26809964.0         1641.0             0.0  Prime Minister of India   \n",
       "2       26809964.0         1641.0             0.0  Prime Minister of India   \n",
       "3       26809964.0         1641.0             0.0  Prime Minister of India   \n",
       "4       26809964.0         1641.0             0.0  Prime Minister of India   \n",
       "\n",
       "  location                               background_image_url  \\\n",
       "0    India  http://pbs.twimg.com/profile_background_images...   \n",
       "1    India  http://pbs.twimg.com/profile_background_images...   \n",
       "2    India  http://pbs.twimg.com/profile_background_images...   \n",
       "3    India  http://pbs.twimg.com/profile_background_images...   \n",
       "4    India  http://pbs.twimg.com/profile_background_images...   \n",
       "\n",
       "               source  \n",
       "0  Twitter Web Client  \n",
       "1  Twitter Web Client  \n",
       "2  Twitter Web Client  \n",
       "3  Twitter Web Client  \n",
       "4  Twitter Web Client  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('C:\\\\Users\\\\nehal\\\\Music\\\\12.NLP\\\\Practise\\\\Datasets\\\\narendramodi_tweets.csv')\n",
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed642d2a",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc19d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the presidents address wonderfully encapsulate...\n",
       "1    rashtrapati jis address to both houses of parl...\n",
       "2    rt pmoindia empowering the marginalised. https...\n",
       "3    rt pmoindia commitment to welfare of farmers. ...\n",
       "4    rt pmoindia improving the quality of life for ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to lower case and extracting only alphabets, spaces and fullstops\n",
    "docs=tweets.text.str.lower().str.replace('[^a-z\\s.]','')\n",
    "docs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf49b9",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420f2bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [the, presidents, address, wonderfully, encaps...\n",
       "1    [rashtrapati, jis, address, to, both, houses, ...\n",
       "2    [rt, pmoindia, empowering, the, marginalised.,...\n",
       "3    [rt, pmoindia, commitment, to, welfare, of, fa...\n",
       "4    [rt, pmoindia, improving, the, quality, of, li...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spliting each review into words\n",
    "docs_tokens=docs.str.split(' ')\n",
    "docs_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de1216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tokens in entire corpus: 56862\n"
     ]
    }
   ],
   "source": [
    "#Putting all tokens into a list \n",
    "tokens_all=[]\n",
    "\n",
    "for x in docs_tokens:\n",
    "    tokens_all.extend(x)\n",
    "print('No. of tokens in entire corpus:',len(tokens_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b6556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c733d2a",
   "metadata": {},
   "source": [
    "### Bag of Word Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0400cf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               4690\n",
       "the            2184\n",
       "to             1516\n",
       "of             1508\n",
       "amp            1480\n",
       "               ... \n",
       "collapse          1\n",
       "hangzhou          1\n",
       "linked            1\n",
       "incentivise       1\n",
       "station           1\n",
       "Length: 10026, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow=pd.Series(tokens_all).value_counts()\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cbefe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af9df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fe29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38a9e261",
   "metadata": {},
   "source": [
    "### Removing Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9dd70",
   "metadata": {},
   "source": [
    "#### Method 1 : Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa1b6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ac2776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amp</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token  frequency\n",
       "0             4690\n",
       "1   the       2184\n",
       "2    to       1516\n",
       "3    of       1508\n",
       "4   amp       1480"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens=pd.DataFrame(bow).reset_index().rename(columns={'index':'token',0:'frequency'})\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619be26",
   "metadata": {},
   "source": [
    "#### Removing common stopword in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6873a74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amp</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rt</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>india</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>people</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>collapse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>hangzhou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023</th>\n",
       "      <td>linked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>incentivise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>station</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9901 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  frequency\n",
       "0                        4690\n",
       "4              amp       1480\n",
       "9               rt        573\n",
       "18           india        298\n",
       "27          people        183\n",
       "...            ...        ...\n",
       "10021     collapse          1\n",
       "10022     hangzhou          1\n",
       "10023       linked          1\n",
       "10024  incentivise          1\n",
       "10025      station          1\n",
       "\n",
       "[9901 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens[~df_tokens['token'].isin(common_stopwords)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb7848b",
   "metadata": {},
   "source": [
    "#### Removing custom stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84a8c8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 3 182\n"
     ]
    }
   ],
   "source": [
    "common_stopwords=nltk.corpus.stopwords.words('english')\n",
    "custom_stopwords=['','amp','rt']\n",
    "all_stopwords=common_stopwords+custom_stopwords\n",
    "print(len(common_stopwords),len(custom_stopwords),len(all_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9df78f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>india</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>people</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pm</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>pmoindia</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>us</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>collapse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>hangzhou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023</th>\n",
       "      <td>linked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>incentivise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>station</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  frequency\n",
       "18           india        298\n",
       "27          people        183\n",
       "29              pm        167\n",
       "36        pmoindia        143\n",
       "40              us        124\n",
       "...            ...        ...\n",
       "10021     collapse          1\n",
       "10022     hangzhou          1\n",
       "10023       linked          1\n",
       "10024  incentivise          1\n",
       "10025      station          1\n",
       "\n",
       "[9898 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens[~df_tokens['token'].isin(all_stopwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929aaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32c26b4d",
   "metadata": {},
   "source": [
    "#### Method 2: Using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9494eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abe912bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       presidents address wonderfully encapsulated in...\n",
       "1       rashtrapati jis address houses parliament inde...\n",
       "2       rt pmoindia empowering marginalised. httpst.co...\n",
       "3       rt pmoindia commitment welfare farmers. httpst...\n",
       "4       rt pmoindia improving quality life poor. https...\n",
       "                              ...                        \n",
       "3215    passage real estate great news aspiring house ...\n",
       "3216    rt dpradhanbjp highlights pradhan mantri ujjwa...\n",
       "3217    successful launch irnssf accomplishment immens...\n",
       "3218    cisfs raising day salute cisf personnel valour...\n",
       "3219                               ... httpst.cooyscfulth\n",
       "Name: text, Length: 3220, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7607b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e337c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba8ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84382ce0",
   "metadata": {},
   "source": [
    "TF-IDF\n",
    "A problem with scoring word frequency is that highly frequent words start to dominate in the document (e.g. larger score), but may not contain as much “informational content” to the model as rarer but perhaps domain specific words.\n",
    "\n",
    "One approach is to rescale the frequency of words by how often they appear in all documents, so that the scores for frequent words like “the” that are also frequent across all documents are penalized.\n",
    "\n",
    "This approach to scoring is called Term Frequency – Inverse Document Frequency, or TF-IDF for short, where:\n",
    "\n",
    "- Term Frequency: is a scoring of the frequency of the word in the current document.\n",
    "- Inverse Document Frequency: is a scoring of how rare the word is across documents.\n",
    "\n",
    "The scores are a weighting where not all words are equally as important or interesting.\n",
    "\n",
    "The scores have the effect of highlighting words that are distinct (contain useful information) in a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdceca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e24ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
